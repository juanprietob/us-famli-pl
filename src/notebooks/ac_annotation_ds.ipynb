{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc52c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from IPython.display import Markdown\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from ipywidgets import VBox, HTML\n",
    "from ipyevents import Event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_point = \"/mnt/raid/C1_ML_Analysis/\"\n",
    "# df_frames = pd.read_csv(os.path.join(mount_point, \"CSV_files/c3_blindsweep_annotation_labels_merged.csv\"))\n",
    "df_frames = pd.read_csv(os.path.join(mount_point, \"CSV_files/c3_blindsweep_annotation_labels_merged_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frames.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76322359",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = \"annotation_id\"\n",
    "img_column = \"file_path\"\n",
    "tag_column = \"tag\"\n",
    "frame_column = \"frame_index\"\n",
    "frame_label=\"annotation_label\"\n",
    "pid = \"pid\"\n",
    "\n",
    "df = df_frames[[id_column, img_column, tag_column, pid]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "frame_label_dict = {\n",
    "    'reject': 0,\n",
    "    'low_visible': 1,\n",
    "    'high_visible': 2,\n",
    "    'low_measurable': 3,\n",
    "    'high_measurable': 4\n",
    "}\n",
    "\n",
    "frame_label_dict_inv = {v: k for k, v in frame_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames = []\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    uid = row[id_column]\n",
    "    frames = df_frames[df_frames[id_column] == uid].sort_values(by=frame_column).reset_index(drop=True)\n",
    "\n",
    "    img_path = os.path.join(mount_point, row[img_column])\n",
    "\n",
    "    img = sitk.ReadImage(img_path)\n",
    "    img_np = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    if img.GetNumberOfComponentsPerPixel() >  1:\n",
    "        img_np = img_np[:,:,:,0]\n",
    "\n",
    "    frame_idx = frames[frame_column].values.tolist()\n",
    "    frame_idx = np.clip(frame_idx, 0, img_np.shape[0]-1)\n",
    "\n",
    "    frame_labels = frames[frame_label].values.tolist()\n",
    "    frame_labels_idx = [frame_label_dict[lbl] for lbl in frame_labels]\n",
    "\n",
    "    img_labels_np = np.zeros(img_np.shape[0])\n",
    "    img_labels_np[frame_idx] = np.array(frame_labels_idx)\n",
    "\n",
    "    file_path_frames = []\n",
    "    img_name = os.path.splitext(row[img_column])[0]\n",
    "    for idx, label in enumerate(img_labels_np):\n",
    "        file_path_frames.append(os.path.join(\"extract_frames_blind_sweeps\", img_name, f\"{idx}.nrrd\"))\n",
    "    df_annotated_frames.append(pd.DataFrame({\n",
    "        \"annotation_id\": uid,\n",
    "        \"file_path\": file_path_frames,\n",
    "        \"annotation_label\": img_labels_np.astype(int).tolist()\n",
    "    }))\n",
    "\n",
    "df_annotated_frames = pd.concat(df_annotated_frames).reset_index(drop=True)\n",
    "df_annotated_frames = df_annotated_frames.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames.hist(column=\"annotation_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccad851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames_filtered = df_annotated_frames[df_annotated_frames['file_path'].apply(lambda x: os.path.exists(os.path.join(mount_point, x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames_filtered['annotation_label'] = df_annotated_frames_filtered['annotation_label'].apply(lambda x: frame_label_dict_inv[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c996ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotated_frames_filtered.to_csv(os.path.join(mount_point, \"CSV_files/c3_blindsweep_annotation_labels_merged_frames_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames_filtered_pred = pd.read_csv(\"test_output/classification/c3_blindsweep_annotation_labels_merged_frames/epoch=9-val_loss=0.27/c3_blindsweep_annotation_labels_merged_frames_prediction.csv\")\n",
    "len(df_annotated_frames_filtered_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309287f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated = pd.read_csv(\"CSV_files/c3_blindsweep_annotation_labels_merged.csv\")[['annotation_id', 'tag', 'pid']].drop_duplicates().reset_index(drop=True)\n",
    "df_annotated_frames_filtered_pred = df_annotated_frames_filtered_pred.merge(df_annotated[['annotation_id', 'tag', 'pid']], on=\"annotation_id\", how=\"left\")\n",
    "len(df_annotated_frames_filtered_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_frames_filtered_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf143940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq(df, sample=-1):\n",
    "    img_seq = []\n",
    "    for fn in df['file_path']:\n",
    "        img = sitk.ReadImage(os.path.join(mount_point, fn))\n",
    "        img_np = sitk.GetArrayFromImage(img)\n",
    "        if img.GetNumberOfComponentsPerPixel() >  1:\n",
    "            img_np = img_np[..., 0]\n",
    "        img_seq.append(img_np)\n",
    "    \n",
    "    img_seq_np = np.array(img_seq)\n",
    "\n",
    "    if sample > 0 and img_seq_np.shape[0] > sample:\n",
    "        ridx = np.random.choice(img_seq_np.shape[0], sample, replace=False)\n",
    "        img_seq_np = img_seq_np[ridx]\n",
    "\n",
    "    return img_seq_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_array_with_arrows(img_np, axis=0, title=\"3D volume viewer\"):\n",
    "    \"\"\"\n",
    "    vol: 3D numpy array\n",
    "    axis: which axis to browse (0,1,2)\n",
    "    Arrow keys:\n",
    "      Left / Right  -> prev / next slice\n",
    "      Up / Down     -> jump -10 / +10 slices\n",
    "      Home / End    -> first / last slice\n",
    "    \"\"\"\n",
    "\n",
    "    # Reorder so browsing axis is first: (S, H, W)\n",
    "    n_slices = img_np.shape[axis]\n",
    "\n",
    "    # Normalize to something nice for display (optional)\n",
    "    vmin, vmax = float(img_np.min()), float(img_np.max())\n",
    "    # Initial slice\n",
    "    idx = 0\n",
    "    slice2d = img_np.take(indices=idx, axis=axis)\n",
    "\n",
    "    # FigureWidget so we can update in-place\n",
    "    fig = go.FigureWidget(\n",
    "        data=[\n",
    "            go.Heatmap(\n",
    "                z=np.flip(slice2d, axis=0),\n",
    "                colorscale=\"Gray\",\n",
    "                zmin=vmin,\n",
    "                zmax=vmax,\n",
    "                showscale=True,\n",
    "            )\n",
    "        ],\n",
    "        layout=go.Layout(\n",
    "            title=f\"{title} — slice {idx+1}/{n_slices} (axis={axis})\",\n",
    "            width=450,\n",
    "            height=450,\n",
    "            margin=dict(l=10, r=10, t=50, b=10),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    status = HTML(value=\"Click inside the output area once, then use arrow keys.\")\n",
    "    box = VBox([status, fig])\n",
    "\n",
    "    # Keyboard event capture\n",
    "    ev = Event(\n",
    "        source=box,\n",
    "        watched_events=[\"keydown\"],\n",
    "        prevent_default_action=True,\n",
    "        bubbles=True,\n",
    "    )\n",
    "\n",
    "    state = {\"idx\": idx}\n",
    "\n",
    "    def update(new_idx):\n",
    "        new_idx = int(np.clip(new_idx, 0, n_slices - 1))\n",
    "        state[\"idx\"] = new_idx\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].z = np.flip(np.take(img_np, indices=new_idx, axis=axis), axis=0)\n",
    "            fig.layout.title = f\"{title} — slice {new_idx+1}/{n_slices} (axis={axis})\"\n",
    "        status.value = (\n",
    "            \"Click inside the output area once, then use arrow keys. \"\n",
    "            f\"Current slice: {new_idx+1}/{n_slices}\"\n",
    "        )\n",
    "\n",
    "    def handle_event(event):\n",
    "        key = event.get(\"key\", \"\")\n",
    "        i = state[\"idx\"]\n",
    "\n",
    "        if key == \"ArrowRight\":\n",
    "            update(i + 1)\n",
    "        elif key == \"ArrowLeft\":\n",
    "            update(i - 1)\n",
    "        elif key == \"ArrowUp\":\n",
    "            update(i + 10)\n",
    "        elif key == \"ArrowDown\":\n",
    "            update(i - 10)\n",
    "        elif key == \"Home\":\n",
    "            update(0)\n",
    "        elif key == \"End\":\n",
    "            update(n_slices - 1)\n",
    "\n",
    "    ev.on_dom_event(handle_event)\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f88791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_arrays_with_arrows_side_by_side(\n",
    "    img_np_a,\n",
    "    img_np_b,\n",
    "    axis=0,\n",
    "    title_a=\"Sweep A\",\n",
    "    title_b=\"Sweep B\",\n",
    "    main_title=\"Sweep viewer\",\n",
    "    share_contrast=True,\n",
    "    width=900,\n",
    "    height=450,\n",
    "):\n",
    "    \"\"\"\n",
    "    Display two 3D numpy arrays side-by-side with synchronized arrow-key slicing.\n",
    "\n",
    "    Arrow keys:\n",
    "      Left / Right  -> prev / next slice\n",
    "      Up / Down     -> jump -10 / +10 slices\n",
    "      Home / End    -> first / last slice\n",
    "\n",
    "    share_contrast:\n",
    "      True  -> common vmin/vmax for both viewers\n",
    "      False -> each viewer uses its own vmin/vmax\n",
    "    \"\"\"\n",
    "    assert img_np_a.ndim == 3 and img_np_b.ndim == 3, \"Both inputs must be 3D numpy arrays\"\n",
    "    assert axis in (0, 1, 2), \"axis must be 0, 1, or 2\"\n",
    "\n",
    "    n_slices_a = img_np_a.shape[axis]\n",
    "    n_slices_b = img_np_b.shape[axis]\n",
    "    n_slices = min(n_slices_a, n_slices_b)\n",
    "\n",
    "    if share_contrast:\n",
    "        vmin = float(min(img_np_a.min(), img_np_b.min()))\n",
    "        vmax = float(max(img_np_a.max(), img_np_b.max()))\n",
    "        vmin_a = vmin_b = vmin\n",
    "        vmax_a = vmax_b = vmax\n",
    "    else:\n",
    "        vmin_a, vmax_a = float(img_np_a.min()), float(img_np_a.max())\n",
    "        vmin_b, vmax_b = float(img_np_b.min()), float(img_np_b.max())\n",
    "\n",
    "    idx = 0\n",
    "    slice_a = np.take(img_np_a, indices=idx, axis=axis)\n",
    "    slice_b = np.take(img_np_b, indices=idx, axis=axis)\n",
    "\n",
    "    # Subplots: 1 row, 2 columns\n",
    "    fig = go.FigureWidget(\n",
    "        make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=(title_a, title_b),\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=np.flip(slice_a, axis=0),\n",
    "            colorscale=\"Gray\",\n",
    "            zmin=vmin_a, zmax=vmax_a,\n",
    "            showscale=True\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=np.flip(slice_b, axis=0),\n",
    "            colorscale=\"Gray\",\n",
    "            zmin=vmin_b, zmax=vmax_b,\n",
    "            showscale=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{main_title} — slice {idx+1}/{n_slices} (axis={axis})\",\n",
    "        width=width,\n",
    "        height=height,\n",
    "        margin=dict(l=10, r=10, t=60, b=10),\n",
    "    )\n",
    "\n",
    "    status = HTML(value=\"Click inside the output area once, then use arrow keys.\")\n",
    "    box = VBox([status, fig])\n",
    "\n",
    "    ev = Event(\n",
    "        source=box,\n",
    "        watched_events=[\"keydown\"],\n",
    "        prevent_default_action=True,\n",
    "        bubbles=True,\n",
    "    )\n",
    "\n",
    "    state = {\"idx\": idx}\n",
    "\n",
    "    def update(new_idx):\n",
    "        new_idx = int(np.clip(new_idx, 0, n_slices - 1))\n",
    "        state[\"idx\"] = new_idx\n",
    "\n",
    "        new_slice_a = np.flip(np.take(img_np_a, indices=new_idx, axis=axis), axis=0)\n",
    "        new_slice_b = np.flip(np.take(img_np_b, indices=new_idx, axis=axis), axis=0)\n",
    "\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].z = new_slice_a  # left heatmap\n",
    "            fig.data[1].z = new_slice_b  # right heatmap\n",
    "            fig.layout.title = f\"{main_title} — slice {new_idx+1}/{n_slices} (axis={axis})\"\n",
    "\n",
    "        status.value = (\n",
    "            \"Click inside the output area once, then use arrow keys. \"\n",
    "            f\"Current slice: {new_idx+1}/{n_slices}\"\n",
    "        )\n",
    "\n",
    "    def handle_event(event):\n",
    "        key = event.get(\"key\", \"\")\n",
    "        i = state[\"idx\"]\n",
    "\n",
    "        if key == \"ArrowRight\":\n",
    "            update(i + 1)\n",
    "        elif key == \"ArrowLeft\":\n",
    "            update(i - 1)\n",
    "        elif key == \"ArrowUp\":\n",
    "            update(i + 10)\n",
    "        elif key == \"ArrowDown\":\n",
    "            update(i - 10)\n",
    "        elif key == \"Home\":\n",
    "            update(0)\n",
    "        elif key == \"End\":\n",
    "            update(n_slices - 1)\n",
    "\n",
    "    ev.on_dom_event(handle_event)\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffca358",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(df_annotated_frames_filtered_pred.groupby(\"annotation_label\")['pred_class'].value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25170d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_seq_np = view_seq('annotation_label == \"reject\" and pred_class == 29')\n",
    "img_seq_np = read_seq(df_annotated_frames_filtered_pred.query('annotation_label == \"high_measurable\" and pred_class == 12'), sample=1000)    \n",
    "\n",
    "# ('high_measurable', 12)\t709\n",
    "# ('high_measurable', 29)\t522\n",
    "# ('high_measurable', 28)\t419\n",
    "# ('high_measurable', 13)\t333\n",
    "# ('high_measurable', 4)\t79\n",
    "# ('high_measurable', 23)\t2\n",
    "# ('high_measurable', 18)\n",
    "# img_seq_np = read_seq('annotation_label == \"high_visible\" and pred_class == 10')\n",
    "\n",
    "plot_3d_array_with_arrows(img_seq_np, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac = pd.read_csv(os.path.join(mount_point, \"test_output/classification/c3_ac_only/epoch=9-val_loss=0.27/extract_frames_blind_sweeps_Dataset_C3_masked_resampled_256_spc075_merged_balanced_ac_only_file_path_prediction.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac['pred_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_seq_np = read_seq(df_annotated_frames_filtered_pred.query('annotation_label == \"high_measurable\" and pred_class == 13').sort_values(by=['annotation_id']), sample=200)\n",
    "# img_seq_np_b = read_seq(df_annotated_frames_filtered_pred.query('annotation_label == \"low_measurable\" and pred_class == 13'), sample=200)\n",
    "img_ac_np = read_seq(df_ac.query('pred_class == 13'), sample=500)\n",
    "\n",
    "# plot_3d_array_with_arrows(img_ac_np, axis=0)\n",
    "plot_3d_arrays_with_arrows_side_by_side(\n",
    "    img_seq_np, img_ac_np, axis=0,\n",
    "    title_a=\"high_measurable 13\", title_b=\"ac 13\",\n",
    "    main_title=\"Compare\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c3_ac_nonac = pd.read_csv(os.path.join(mount_point, \"test_output/classification/c3_ac_non_ac_balanced/epoch=9-val_loss=0.27/extract_frames_blind_sweeps_Dataset_C3_masked_resampled_256_spc075_merged_balanced_ac_nonac_prediction.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c3_ac_nonac['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_c3_ac_nonac_filterd = df_c3_ac_nonac[df_c3_ac_nonac['tag'].isin(['AC', 'BPD', 'TCD', 'FL', 'HL', 'CRL'])]\n",
    "df_c3_ac_nonac_filterd = df_c3_ac_nonac[df_c3_ac_nonac['tag'].isin(['FL'])]\n",
    "\n",
    "# FL: 20, 14, 2, 5, 7\n",
    "\n",
    "Markdown(df_c3_ac_nonac_filterd[['tag', 'pred_class']].value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_seq_np = view_seq('annotation_label == \"reject\" and pred_class == 29')\n",
    "img_seq_np = read_seq(df_c3_ac_nonac.query('tag == \"FL\" and pred_class == 2'))\n",
    "\n",
    "# ('high_measurable', 12)\t709\n",
    "# ('high_measurable', 29)\t522\n",
    "# ('high_measurable', 28)\t419\n",
    "# ('high_measurable', 13)\t333\n",
    "# ('high_measurable', 4)\t79\n",
    "# ('high_measurable', 23)\t2\n",
    "# ('high_measurable', 18)\n",
    "# img_seq_np = read_seq('annotation_label == \"high_visible\" and pred_class == 10')\n",
    "\n",
    "plot_3d_array_with_arrows(img_seq_np, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ac_rank_ac = {\n",
    "    1.0: [{'tag': 'AC', 'pred_class': 29}, {'tag': 'AC', 'pred_class': 28}],\n",
    "    0.9: [{'tag': 'AC', 'pred_class': 13}],\n",
    "    0.8: [{'tag': 'AC', 'pred_class': 12}],\n",
    "    0.0: [{'tag': 'BPD', 'pred_class': 6}, \n",
    "          {'tag': 'BPD', 'pred_class': 11}, \n",
    "          {'tag': 'BPD', 'pred_class': 25},\n",
    "          {'tag': 'BPD', 'pred_class': 26},\n",
    "          {'tag': 'BPD', 'pred_class': 32}, \n",
    "          {'tag': 'BPD', 'pred_class': 16},\n",
    "          {'tag': 'FL', 'pred_class': 20},\n",
    "          {'tag': 'FL', 'pred_class': 14},\n",
    "          {'tag': 'FL', 'pred_class': 2},\n",
    "          {'tag': 'HL', 'pred_class': 20},\n",
    "          {'tag': 'HL', 'pred_class': 14},\n",
    "          {'tag': 'HL', 'pred_class': 2}],\n",
    "}\n",
    "\n",
    "ac_rank_annot = {\n",
    "    0.8: [{'annotation_label': 'high_measurable', 'pred_class': 12, 'samples': 200}, \n",
    "          {'annotation_label': 'high_measurable', 'pred_class': 13, 'samples': 100}],\n",
    "    0.75: [{'annotation_label': 'low_measurable', 'pred_class': 13, 'samples': 500}],\n",
    "    0.7: [{'annotation_label': 'low_measurable', 'pred_class': 12, 'samples': 500}],\n",
    "    0.6: [{'annotation_label': 'high_visible', 'pred_class': 13, 'samples': 1000}],\n",
    "    0.5: [{'annotation_label': 'high_visible', 'pred_class': 12, 'samples': 1000},\n",
    "          {'annotation_label': 'low_visible', 'pred_class': 13, 'samples': 1000},\n",
    "          {'annotation_label': 'low_measurable', 'pred_class': 4, 'samples': 50}],\n",
    "    0.4: [{'annotation_label': 'high_visible', 'pred_class': 4, 'samples': 500},\n",
    "          {'annotation_label': 'low_measurable', 'pred_class': 10, 'samples': 10}],\n",
    "    0.3: [{'annotation_label': 'low_visible', 'pred_class': 4, 'samples': 2000},\n",
    "          {'annotation_label': 'low_visible', 'pred_class': 12, 'samples': 500},\n",
    "          {'annotation_label': 'high_visible', 'pred_class': 10, 'samples': 100}],\n",
    "    0.2: [{'annotation_label': 'low_visible', 'pred_class': 10, 'samples': 1000},\n",
    "          {'annotation_label': 'reject', 'pred_class': 4, 'samples': 1000}],\n",
    "    0.0: [\n",
    "        {'annotation_label': \"reject\", 'pred_class': 14, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 5, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 21, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 24, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 23, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 1, 'samples': 200}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 33, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 15, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 22, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 10, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 30, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 20, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 18, 'samples': 500}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 7, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 0, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 31, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 8, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 9, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 27, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 3, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 2, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 32, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 17, 'samples': 100}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 6, 'samples': 1000}, \n",
    "        {'annotation_label': \"reject\", 'pred_class': 11, 'samples': 954},\n",
    "        {'annotation_label': \"reject\", 'pred_class': 34, 'samples': 100},\n",
    "        {'annotation_label': \"reject\", 'pred_class': 16, 'samples': 700},\n",
    "        {'annotation_label': \"reject\", 'pred_class': 26, 'samples': 556},\n",
    "        {'annotation_label': \"reject\", 'pred_class': 19, 'samples': 374},\n",
    "        {'annotation_label': \"reject\", 'pred_class': 25, 'samples': 338}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494af861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_ac_simn = []\n",
    "for score in ac_rank_ac.keys():\n",
    "    samples = ac_rank_ac[score]\n",
    "    for sample in samples:\n",
    "        query = \"\"\n",
    "        for key in sample.keys():\n",
    "            if key != 'samples':\n",
    "                if isinstance(sample[key], str):\n",
    "                    query += f\"{key} == '{sample[key]}' and \"\n",
    "                else:\n",
    "                    query += f\"{key} == {sample[key]} and \"\n",
    "        query = query[:-5]\n",
    "        ds = df_c3_ac_nonac.query(query)[['file_path', 'pid', 'tag', 'pred_class']]\n",
    "        if('samples' in sample):\n",
    "            ds_s = ds.sample(n=sample['samples'], random_state=25)\n",
    "        else:\n",
    "            ds_s = ds\n",
    "\n",
    "        ds_s['score'] = score\n",
    "        df_ac_simn.append(ds_s)\n",
    "\n",
    "for score in ac_rank_annot.keys():\n",
    "    samples = ac_rank_annot[score]\n",
    "    for sample in samples:\n",
    "        query = \"\"\n",
    "        for key in sample.keys():\n",
    "            if key != 'samples':\n",
    "                if isinstance(sample[key], str):\n",
    "                    query += f\"{key} == '{sample[key]}' and \"\n",
    "                else:\n",
    "                    query += f\"{key} == {sample[key]} and \"\n",
    "        query = query[:-5]\n",
    "        ds = df_annotated_frames_filtered_pred.query(query)[['file_path', 'annotation_id', 'annotation_label', 'pid', 'tag', 'pred_class']]\n",
    "        if('samples' in sample):\n",
    "            ds_s = ds.sample(n=sample['samples'], random_state=25)\n",
    "        else:\n",
    "            ds_s = ds\n",
    "        ds_s['score'] = score\n",
    "        df_ac_simn.append(ds_s)\n",
    "\n",
    "df_ac_simn = pd.concat(df_ac_simn).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac_simn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8960b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac_simn.hist(column=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_seq_simn = read_seq(df_ac_simn.query('score == 0.2'), sample=500)\n",
    "\n",
    "plot_3d_array_with_arrows(img_seq_simn, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cef523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac_simn.to_csv(os.path.join(mount_point, \"CSV_files/c3_blindsweep_annotation_labels_merged_train_v0.1_ac_simn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test():\n",
    "    df_test = pd.read_csv(os.path.join(mount_point, \"test_output/classification/c3_blindsweep_annotation_labels_merged_frames_test/epoch=9-val_loss=0.27/c3_blindsweep_annotation_labels_merged_frames_test_prediction.csv\"))\n",
    "    df_test_score = []\n",
    "\n",
    "    for score in ac_rank_annot.keys():\n",
    "        samples = ac_rank_annot[score]\n",
    "        for sample in samples:\n",
    "            query = \"\"\n",
    "            for key in sample.keys():\n",
    "                if key != 'samples':\n",
    "                    if isinstance(sample[key], str):\n",
    "                        query += f\"{key} == '{sample[key]}' and \"\n",
    "                    else:\n",
    "                        query += f\"{key} == {sample[key]} and \"\n",
    "            query = query[:-5]\n",
    "            ds_t = df_test.query(query)\n",
    "            # if('samples' in sample):\n",
    "            #     ds_s = ds.sample(n=sample['samples'], random_state=25)\n",
    "            # else:\n",
    "            #     ds_s = ds\n",
    "            ds_t['score'] = score\n",
    "            df_test_score.append(ds_t)\n",
    "\n",
    "\n",
    "    df_test_score = pd.concat(df_test_score).reset_index(drop=True)\n",
    "\n",
    "    df_missing = df_test[~df_test['file_path'].isin(df_test_score['file_path'])]\n",
    "\n",
    "    ac_rank_missing = {\n",
    "        0.8: [{'pred_class': 29},\n",
    "            {'pred_class': 28}],\n",
    "        0.0: [{\"pred_class\":0},\n",
    "                {\"pred_class\":1},\n",
    "                {\"pred_class\":2},\n",
    "                {\"pred_class\":3},\n",
    "                {\"pred_class\":5},\n",
    "                {\"pred_class\":7},\n",
    "                {\"pred_class\":8},\n",
    "                {\"pred_class\":11},\n",
    "                {\"pred_class\":12},\n",
    "                {\"pred_class\":13},\n",
    "                {\"pred_class\":14},\n",
    "                {\"pred_class\":17},\n",
    "                {\"pred_class\":18},\n",
    "                {\"pred_class\":19},\n",
    "                {\"pred_class\":20},\n",
    "                {\"pred_class\":21},\n",
    "                {\"pred_class\":22},\n",
    "                {\"pred_class\":23},\n",
    "                {\"pred_class\":24},\n",
    "                {\"pred_class\":27},\n",
    "                {\"pred_class\":30},\n",
    "                {\"pred_class\":31},\n",
    "                {\"pred_class\":32},\n",
    "                {\"pred_class\":33},\n",
    "                {\"pred_class\":34}]\n",
    "    }\n",
    "\n",
    "    df_missing_score = []\n",
    "    for score in ac_rank_missing.keys():\n",
    "        samples = ac_rank_missing[score]\n",
    "        for sample in samples:\n",
    "            query = \"\"\n",
    "            for key in sample.keys():\n",
    "                if key != 'samples':\n",
    "                    if isinstance(sample[key], str):\n",
    "                        query += f\"{key} == '{sample[key]}' and \"\n",
    "                    else:\n",
    "                        query += f\"{key} == {sample[key]} and \"\n",
    "            query = query[:-5]\n",
    "            ds_t = df_missing.query(query)\n",
    "            # if('samples' in sample):\n",
    "            #     ds_s = ds.sample(n=sample['samples'], random_state=25)\n",
    "            # else:\n",
    "            #     ds_s = ds\n",
    "            ds_t['score'] = score\n",
    "            df_missing_score.append(ds_t)\n",
    "\n",
    "    df_missing_score = pd.concat(df_missing_score).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    df_test_score = pd.concat([df_test_score, df_missing_score]).reset_index(drop=True)\n",
    "\n",
    "    df_missing = df_test[~df_test['file_path'].isin(df_test_score['file_path'])]\n",
    "\n",
    "    df_missing\n",
    "\n",
    "    df_test_score.to_csv(os.path.join(mount_point, \"CSV_files/c3_blindsweep_annotation_labels_merged_ac_simn_test.csv\"), index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6a43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
